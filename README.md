# rag_local_pdfs
This project implements a Retrieval-Augmented Generation (RAG) system using local PDF documents as the knowledge base. Built with LangChain, ChromaDB, and a local LLM via Ollama, this setup enables question-answering over your own documents using efficient vector search and contextual responses from LLMs.
